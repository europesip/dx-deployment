#********************************************************************
#* Licensed Materials - Property of HCL                             *
#*                                                                  *
#* Copyright HCL Technologies Ltd. 2023, 2025. All Rights Reserved. *
#*                                                                  *
#* Note to US Government Users Restricted Rights:                   *
#*                                                                  *
#* Use, duplication or disclosure restricted by GSA ADP Schedule    *
#********************************************************************

# Default values for hcl-dx-search.

# Image related configuration
images:
  # Image pulling behavior, accepts: Always, Never, IfNotPresent
  pullPolicy: "IfNotPresent"
  # Image pull secrets used for accessing the repository
  # Secret must be annotated: - name: <SECRETNAME>
  imagePullSecrets:
  # Container repository used to retrieve the images
  repository: ""
  # Image tag for each application
  tags:
    openSearch: "v2.0.0_20251024-1408"
    searchMiddleware: "v2.0.0_20251025-2200"
    fileProcessor: "v2.0.0_20251024-1351"
  # Image name for each application
  names:
    openSearch: "dx/opensearch"
    searchMiddleware: "dx/opensearch-middleware"
    fileProcessor: "dx/file-processor"

# Resource allocation settings, definition per pod
# Use number + unit, e.g. 1500m for CPU or 1500M for Memory
resources:
  openSearchManager:
    requests:
      cpu: "1000m"
      memory: "2048Mi"
    limits:
      cpu: "1000m"
      memory: "2048Mi"
  openSearchData:
    requests:
      cpu: "1000m"
      memory: "2048Mi"
    limits:
      cpu: "1000m"
      memory: "2048Mi"
  searchMiddlewareQuery:
    requests:
      cpu: "500m"
      memory: "768Mi"
    limits:
      cpu: "500m"
      memory: "768Mi"
  searchMiddlewareData:
    requests:
      cpu: "500m"
      memory: "768Mi"
    limits:
      cpu: "500m"
      memory: "768Mi"
  fileProcessor:
    requests:
      cpu: "1000m"
      memory: "2048Mi"
    limits:
      cpu: "1000m"
      memory: "2048Mi"    

# Annotations for different DX Resources.
# Type: Array of objects
# Sample "annotations" configuration:
#   annotations:
#     service:
#       core:
#         - key: KEY1
#           value: VALUE1
#         - key: KEY2
#           value: VALUE2
annotations:
  # Service annotations for DX Resources
  service:
    openSearchManager: []
    openSearchData: []
    searchMiddlewareQuery: []
    searchMiddlewareData: []
    fileProcessor: []
  # Pod annotations for DX Resources
  pod:
    openSearchManager: []
    openSearchData: []
    searchMiddlewareQuery: []
    searchMiddlewareData: []
    fileProcessor: []

# Labels for different DX Resources.
# Type: Array of objects
# Sample "labels" configuration:
#   labels:
#     service:
#       haproxy:
#         - key: KEY1
#           value: VALUE1
#         - key: KEY2
#           value: VALUE2
labels:
  # Service annotations for DX Resources
  service:
    openSearchManager: []
    openSearchData: []
    searchMiddlewareQuery: []
    searchMiddlewareData: []
    fileProcessor: []
  # Pod annotations for DX Resources
  pod:
    openSearchManager: []
    openSearchData: []
    searchMiddlewareQuery: []
    searchMiddlewareData: []
    fileProcessor: []

# Scaling settings for deployed applications
scaling:
  # The default amount of replicas per application
  replicas:
    openSearchManager: 1
    openSearchData: 1
    # If split deployment is enabled, both values are considered
    # In non split deployment, only the query value is considered
    searchMiddlewareQuery: 1
    searchMiddlewareData: 1
    fileProcessor: 1
  # Automated scaling using HorizontalPodAutoScaler
  horizontalPodAutoScaler:
    searchMiddlewareQuery:
      # Enable or disable autoscaling
      enabled: false
      # Minimum and maximum Pod count
      minReplicas: 1
      maxReplicas: 3
      # Target CPU utilization scaling threshold
      targetCPUUtilizationPercentage: 75
      # Target Memory utilization scaling threshold
      targetMemoryUtilizationPercentage: 80
    searchMiddlewareData:
      # Enable or disable autoscaling
      enabled: false
      # Minimum and maximum Pod count
      minReplicas: 1
      maxReplicas: 3
      # Target CPU utilization scaling threshold
      targetCPUUtilizationPercentage: 75
      # Target Memory utilization scaling threshold
      targetMemoryUtilizationPercentage: 80
    fileProcessor:
      # Enable or disable autoscaling
      enabled: false
      # Minimum and maximum Pod count
      minReplicas: 1
      maxReplicas: 3
      # Target CPU utilization scaling threshold
      targetCPUUtilizationPercentage: 75
      # Target Memory utilization scaling threshold
      targetMemoryUtilizationPercentage: 80

# Application specific node selector
# nodeSelector uses following notation: <NODE_LABEL_KEY>: <NODE_LABEL_VALUE>
# e.g. diskType: ssd
nodeSelector:
  openSearchManager:
  openSearchData:
  # If split deployment is enabled, both values are considered
  # In non split deployment, only the query value is considered
  searchMiddlewareQuery:
  searchMiddlewareData:
# Affinity and anti-affinity expands the types of constraints you can define
# e.g affinity
# affinity:
#   openSearchManager:
#     nodeAffinity:
#       requiredDuringSchedulingIgnoredDuringExecution:
#         nodeSelectorTerms:
#           - matchExpressions:
#               - key: topology.kubernetes.io/zone
#                 operator: In
#                 values:
#                   - antarctica-east1
#                   - antarctica-west1
#       preferredDuringSchedulingIgnoredDuringExecution:
#         - weight: 1
#           preference:
#             matchExpressions:
#               - key: another-node-label-key
#                 operator: In
#                 values:
#                   - another-node-label-value
#     podAffinity:
#       requiredDuringSchedulingIgnoredDuringExecution:
#         - labelSelector:
#             matchExpressions:
#               - key: security
#                 operator: In
#                 values:
#                   - S1
#           topologyKey: topology.kubernetes.io/zone
#     podAntiAffinity:
#       preferredDuringSchedulingIgnoredDuringExecution:
#         - weight: 100
#           podAffinityTerm:
#             labelSelector:
#               matchExpressions:
#                 - key: security
#                   operator: In
#                   values:
#                     - S2
#             topologyKey: topology.kubernetes.io/zone
affinity:
  openSearchManager:
  openSearchData:
  searchMiddlewareQuery:
  searchMiddlewareData:

# nodeName is a field in the Pod spec. If the nodeName field is not empty, the scheduler ignores the Pod and the kubelet on the named node tries to place the Pod on that node.
# e.g nodeName
# nodeName:
#   openSearchManager: "node-0"
nodeName:
  openSearchManager: ""
  openSearchData: ""
  searchMiddlewareQuery: ""
  searchMiddlewareData: ""
  fileProcessor: ""

# Tolerations are applied to pods. Tolerations allow the scheduler to schedule pods with matching taints.
# e.g tolerations
# tolerations:
#   openSearchManager:
#   - key: "key1"
#     operator: "Equal"
#     value: "value1"
#     effect: "NoSchedule"
tolerations:
  openSearchManager:
  openSearchData:
  searchMiddlewareQuery:
  searchMiddlewareData:

# You can use topology spread constraints to control how Pods are spread across your cluster among failure-domains such as regions, zones, nodes, or among any other topology domains that you define.
# e.g topologySpreadConstraints:
# topologySpreadConstraints:
#   openSearchManager:
#   - maxSkew: 1
#     topologyKey: zone
#     whenUnsatisfiable: DoNotSchedule #ScheduleAnyway
#     labelSelector:
#       matchLabels:
#         app: app-openSearchManager
topologySpreadConstraints:
  openSearchManager:
  openSearchData:
  searchMiddlewareQuery:
  searchMiddlewareData:

# Persistent Volume Setup
volumes:
  # Persistent Volumes for OpenSearch
  openSearchManager:
    # Data persistence for OpenSearch nodes
    data: 
      storageClassName: "manual"
      requests:
        storage: "1Gi"
      # Optional label selector to further filter the set of volumes. Only the volumes whose labels match the selector can be bound to the claim.
      selector:
      # Optional volume name to specifically map to
      volumeName:
    # List of optional additional PVCs for customer applications
    # Each list element must include a unique "name", one or more "accessModes"
    # from the options ReadWriteOnce, ReadOnlyMany or ReadWriteMany, a "mountPath" specifying where in the
    # core container it should be mounted, a "storageClassName" and a size in "requests/storage".
    # It may also optionally include a "selector" section to select specific PVs based on their labels.
    # It may also optionally include a "volumeName" to select a specific PV.
    # Example:
    # customPVCs:
    #   - name: "test1"
    #     accessModes:
    #       - "ReadWriteMany"
    #     mountPath: "/opt/HCL/test1"
    #     storageClassName: "manual"
    #     requests:
    #       storage: "20Gi"
    #     selector:
    #       matchLabels:
    #         label: test
    #       matchExpressions:
    #         - key: name
    #           operator: In
    #           values:
    #             - test1
    #             - test2
    #     volumeName: "test-pv"
    customPVCs: []
  openSearchData:
    # Data persistence for OpenSearch nodes
    data: 
      storageClassName: "manual"
      requests:
        storage: "1Gi"
      # Optional label selector to further filter the set of volumes. Only the volumes whose labels match the selector can be bound to the claim.
      selector:
      # Optional volume name to specifically map to
      volumeName:
    # List of optional additional PVCs for customer applications
    # Each list element must include a unique "name", one or more "accessModes"
    # from the options ReadWriteOnce, ReadOnlyMany or ReadWriteMany, a "mountPath" specifying where in the
    # core container it should be mounted, a "storageClassName" and a size in "requests/storage".
    # It may also optionally include a "selector" section to select specific PVs based on their labels.
    # It may also optionally include a "volumeName" to select a specific PV.
    # Example:
    # customPVCs:
    #   - name: "test1"
    #     accessModes:
    #       - "ReadWriteMany"
    #     mountPath: "/opt/HCL/test1"
    #     storageClassName: "manual"
    #     requests:
    #       storage: "20Gi"
    #     selector:
    #       matchLabels:
    #         label: test
    #       matchExpressions:
    #         - key: name
    #           operator: In
    #           values:
    #             - test1
    #             - test2
    #     volumeName: "test-pv"
    customPVCs: []

# Controls which application is deployed and configured
applications:
  # Deploys openSearch
  openSearch: true
  # Deploys the search middleware
  searchMiddleware: true
  # Deploys file processor
  fileProcessor: false

# Security related configuration, e.g. default credentials
security:
  # Security configuration for Search administration
  administration:
    # Username of the search administrator.
    searchAdminUser: "searchadmin"
    # Password of the search administrator.
    searchAdminPassword: "adminsearch"
    # Provide a custom secret that will be used to set credentials for administration
    # If customSearchAdminSecret is provided then searchAdminUser & searchAdminPassword values are ignored
    # Required attributes:
    # data:
    #   username: value
    #   password: value
    customSearchAdminSecret: ""
    # Token expiry time in seconds
    tokenExpiry: 1800
    # Token secret used to generate JWT
    tokenSecret: ""
    # Token secret name containing the secret for the JWT generation
    # If provided value of tokenSecret will be ignored
    # Required attributes:
    # data:
    #   secret: "value"
    customTokenSecretSecret: ""
  # Security configuration for push admin
  pushAdministration:
    # Username of the push administrator.
    pushAdminUser: "pushadmin"
    # Password of the push administrator.
    pushAdminPassword: "adminpush"
    # Provide a custom secret that will be used to set credentials for push administration
    # If customPushAdminSecret is provided then pushAdminUser & pushAdminPassword values are ignored
    # Required attributes:
    # data:
    #   username: value
    #   password: value
    customPushAdminSecret: ""
    # Token expiry time in seconds
    tokenExpiry: 1800
    # Token secret used to generate JWT
    tokenSecret: ""
    # Token secret name containing the secret for the JWT generation
    # If provided value of tokenSecret will be ignored
    # Required attributes:
    # data:
    #   secret: "value"
    customTokenSecretSecret: "" 
  openSearch:
    # Admin certificate secret
    adminCertSecret: "search-admin-cert"
    # Node certificate secret
    nodeCertSecret: "search-node-cert"
    # Client certificate secret
    clientCertSecret: "search-client-cert"

# Kubernetes probe configuration for application Pods
probes:
  # OpenSearch probe configuration
  openSearch:
    # Liveness probe using the applications HTTP probe endpoint
    livenessProbe:
      failureThreshold: 10
      initialDelaySeconds: 30
      periodSeconds: 30
      successThreshold: 1
      timeoutSeconds: 15
    # Readiness probe using the applications HTTP probe endpoint
    readinessProbe:
      failureThreshold: 3
      initialDelaySeconds: 30
      periodSeconds: 15
      successThreshold: 1
      timeoutSeconds: 10
  # Search middleware probe configuration
  searchMiddleware:
    # Liveness probe using the applications HTTP probe endpoint
    livenessProbe:
      failureThreshold: 4
      initialDelaySeconds: 30
      periodSeconds: 30
      successThreshold: 1
      timeoutSeconds: 30
    # Readiness probe using the applications HTTP probe endpoint
    readinessProbe:
      failureThreshold: 2
      initialDelaySeconds: 30
      periodSeconds: 30
      successThreshold: 1
      timeoutSeconds: 30
  # File processor probe configuration
  fileProcessor:
    # Liveness probe using the applications HTTP probe endpoint
    livenessProbe:
      failureThreshold: 3
      initialDelaySeconds: 30
      periodSeconds: 30
      successThreshold: 1
      timeoutSeconds: 15
    # Readiness probe using the applications HTTP probe endpoint  
    readinessProbe:
      failureThreshold: 3
      initialDelaySeconds: 30
      periodSeconds: 15
      successThreshold: 1
      timeoutSeconds: 10    

# Logging configuration
logging:
  # OpenSearch logging configuration
  openSearch:
    level: 
      - ""
  # Search middleware logging configuration
  searchMiddleware:
    level: 
      - "api:server-v2:*=info"

# Application specific metrics
metrics:
  # Metrics for OpenSearch
  openSearch:
    # Determine if the Content Composer metrics are scraped by prometheus
    scrape: true
    # Determines the way Prometheus discovers the metrics of a service
    # Accepts: "annotation" or "serviceMonitor"
    #   "annotation" - adds the Prometheus annotation to the deployment that can be discovered by Prometheus
    #   "serviceMonitor" - creates a ServiceMonitor custom resource that can be discovered by Prometheus Operator
    # The "serviceMonitor" setting requires the ServiceMonitor CRD to be installed in the cluster which comes with Prometheus Operator
    prometheusDiscoveryType: "annotation"
  # Metrics for search middleware
  searchMiddleware:
    # Determine if the Content Composer metrics are scraped by prometheus
    scrape: true
    # Determines the way Prometheus discovers the metrics of a service
    # Accepts: "annotation" or "serviceMonitor"
    #   "annotation" - adds the Prometheus annotation to the deployment that can be discovered by Prometheus
    #   "serviceMonitor" - creates a ServiceMonitor custom resource that can be discovered by Prometheus Operator
    # The "serviceMonitor" setting requires the ServiceMonitor CRD to be installed in the cluster which comes with Prometheus Operator
    prometheusDiscoveryType: "annotation"
  # Metrics for file processor
  fileProcessor:
    # Determine if the Content Composer metrics are scraped by prometheus
    scrape: true
    # Determines the way Prometheus discovers the metrics of a service
    # Accepts: "annotation" or "serviceMonitor"
    #   "annotation" - adds the Prometheus annotation to the deployment that can be discovered by Prometheus
    #   "serviceMonitor" - creates a ServiceMonitor custom resource that can be discovered by Prometheus Operator
    # The "serviceMonitor" setting requires the ServiceMonitor CRD to be installed in the cluster which comes with Prometheus Operator
    prometheusDiscoveryType: "annotation"

# Application configuration
configuration:
  # Application specific configuration for OpenSearch
  openSearch:
    # Controls if the OpenSearch roles are split into manager and data pods
    # If false, all roles are combined into the manager pods and no additional data pods are created
    # If true, the there will be distinct manager and data pods, which can be configured individually
    splitDeployment: false
    # JVM Options for the manager pods, adjusting the JVM to the configured memory settings    
    jvmOptionsManager: "-Xmx1024M -Xms1024M"
    # JVM Options for the data pods, adjusting the JVM to the configured memory settings    
    jvmOptionsData: "-Xmx1024M -Xms1024M"
  # Application specific configuration for the search middleware
  searchMiddleware:
    # Controls if the data and query load should be split between Pods or not
    splitDeployment: false 
    # Cors origin for search middleware
    corsOrigin: []
    # Host of search middleware
    host: ""
    # Port of search middleware
    port:
    # Setting if SSL is enabled for Search middleware
    ssl: false
    # Version of Search Middleware
    version: "v2"
  # To change the timezone of all the containers. This value should be a valid timezone format (i.e. Australia/Melbourne, Europe/London, America/Phoenix).
  containerTimezone: ""
  # Automated setup
  automatedSetup:
    # Name of the DX helm deployment, needs to be configured with the value that has been used
    # during the DX deployment in the same namespace
    dxDeploymentName: "dx-deployment"
    # Configuring DAM automatically
    digitalAssetManagement: 
      # Enable or disable DAM automated setup
      enabled: true
      # Override for the UUID that is being used for the default DAM collection
      uuid: ""
      # Host to perform ACL lookups from, if empty the middleware will try to detect the host
      # It will try to use the haproxy service of the DX deployment in the same namespace
      aclLookupHost: ""
      # Path to perform ACL lookups from, if empty the middleware will try to detect the right path
      aclLookupPath: ""
    # Configuring WCM automatically
    wcm:
      # Enable or disable WCM automated setup
      enabled: true
      # Override for the UUID that is being used for the default WCM collection
      uuid: ""
      # Host to perform ACL lookups from, if empty the middleware will try to detect the host
      # It will try to use the haproxy service of the DX deployment in the same namespace
      aclLookupHost: ""
      # Path to perform ACL lookups from, if empty the middleware will try to detect the right path
      aclLookupPath: ""
      # Override for the crawler UUID that is being used for the default WCM crawler
      crawlerUuid: ""
      # Schedule of the default WCM crawler, default is every 15 minutes
      crawlerSchedule: "*/15 * * * *"
    # Configuring JCR automatically
    jcr:
      # Enable or disable JCR automated setup
      enabled: true
      # Override for the UUID that is being used for the default JCR collection
      uuid: ""
      # Host to perform ACL lookups from, if empty the middleware will try to detect the host
      # It will try to use the haproxy service of the DX deployment in the same namespace
      aclLookupHost: ""
      # Path to perform ACL lookups from, if empty the middleware will try to detect the right path
      aclLookupPath: ""
      # Override for the crawler UUID that is being used for the default JCR crawler
      crawlerUuid: ""
      # Schedule of the default JCR crawler, default is every 15 minutes
      crawlerSchedule: "*/15 * * * *"
    # Configuring Portal automatically
    portal:
      # Enable or disable Portal automated setup
      enabled: true
      # Override for the UUID that is being used for the default Portal collection
      uuid: ""
      # Path to perform ACL lookups from, if empty the middleware will try to detect the right path
      aclLookupPath: ""
      # Host to perform ACL lookups from, if empty the middleware will try to detect the host
      # It will try to use the haproxy service of the DX deployment in the same namespace
      aclLookupHost: ""
      # Override for the crawler UUID that is being used for the default Portal crawler
      crawlerUuid: ""
      # Schedule of the default Portal crawler, default is every 15 minutes
      crawlerSchedule: "*/15 * * * *"
    # Configuring People Service automatically
    people:
      # Enable or disable People Service automated setup
      enabled: true
      # Override for the UUID that is being used for the default People Service collection
      uuid: ""
      # Host to perform ACL lookups from, if empty the middleware will try to detect the host
      # It will try to use the haproxy service of the DX deployment in the same namespace
      aclLookupHost: ""
      # Path to perform ACL lookups from, if empty the middleware will try to detect the right path
      aclLookupPath: ""
  # Configuration for text extraction
  textExtraction:
    # Configuring Fileprocessor
    allowedMimeTypes:
      - "application/vnd.openxmlformats-officedocument.wordprocessingml.document"
      - "application/msword"
      - "application/vnd.ms-word.document.macroEnabled.12"
      - "application/vnd.openxmlformats-officedocument.wordprocessingml.template"
      - "application/vnd.ms-word.template.macroEnabled.12"
      - "application/vnd.ms-excel"
      - "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
      - "application/vnd.ms-excel.sheet.macroEnabled.12"
      - "application/vnd.openxmlformats-officedocument.spreadsheetml.template"
      - "application/vnd.ms-excel.template.macroEnabled.12"
      - "application/vnd.ms-powerpoint"
      - "application/vnd.openxmlformats-officedocument.presentationml.presentation"
      - "application/vnd.ms-powerpoint.presentation.macroEnabled.12"
      - "application/vnd.openxmlformats-officedocument.presentationml.slideshow"
      - "application/vnd.ms-powerpoint.slideshow.macroEnabled.12"
      - "application/vnd.openxmlformats-officedocument.presentationml.template"
      - "application/vnd.ms-powerpoint.template.macroEnabled.12"
      - "application/vnd.ms-powerpoint.addin.macroEnabled.12"
      - "application/rtf"
      - "text/plain"
      - "application/pdf"
      - "text/csv"
      - "text/markdown"
      - "application/vnd.oasis.opendocument.text"
      - "application/vnd.oasis.opendocument.spreadsheet"
      - "application/vnd.oasis.opendocument.presentation"
      - "application/vnd.oasis.opendocument.graphics"
      - "application/vnd.oasis.opendocument.chart"
      - "application/vnd.oasis.opendocument.formula"
  picker:
    contextRoot:
      # Context root of Search Middleware
      api: "/dx/api/search"
      # Context root of Picker UI
      ui: "/dx/ui/search/picker"

# Custom environment variables
environment:
  # Pod environment variables for DX Resources
  # WARNING: This environment variable only applies to Pod's main container and will not apply to other containers of the Pod (i.e., logging sidecar, prereqs checker).
  pod:
    openSearchManager: []
    openSearchData: []
    searchMiddlewareQuery: []
    searchMiddlewareData: []
    fileProcessor: []

# Allows to start a Pod and its containers in maintenance mode.
# Pods will not perform a regular execute of the application but will remain idle
# This allows for debugging inside the containers if required, e.g. if configuration fixes are required
maintenanceMode:
    openSearchManager: false
    openSearchData: false
    searchMiddlewareQuery: false
    searchMiddlewareData: false
    fileProcessor: false

commonFieldMappings:
  # Mappings for WCM Crawler
  wcm:
    title: "title"
    description: "summary"
    type: "documentType"
    tags: "tags"
  # Mappings for DAM
  dam:
    title: "name"
    description: "description"
    type: "type"
    tags: "tags"
  # Mappings for JCR Crawler
  jcr:
    title: "title"
    description: "description"
    type: "category"
    tags: ""
  # Mappings for Portal Crawler
  portal:
    title: "title"
    description: "summary"
    type: "category"
    tags: "tags"    

# Global configurations
# This configuration is only relevant for the SoFy deployments.
global:
  hclImagePullSecret:
  hclImageRegistry: "hclcr.io/sofy"
  persistence:
    rwxStorageClassV3:

